{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import different modules for using with the notebook\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as logis\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - three randomly-generated Gaussian-distributed clouds of points in 2d space\n",
    "np.random.seed(0)\n",
    "# Number of points\n",
    "N = 1000\n",
    "# Labels for each cluster\n",
    "y = np.random.randint(low=0, high=2+1, size = N)\n",
    "# Mean of each cluster\n",
    "means = np.array([[-1, 1, -1], [-1, 1, 1],])\n",
    "# Covariance (in X and Y direction) of each cluster\n",
    "covariances = np.random.random_sample((2, 3)) + 1\n",
    "# Dimensions of each point\n",
    "X = np.vstack([np.random.randn(N)*covariances[0, y] + means[0, y],\n",
    "               np.random.randn(N)*covariances[1, y] + means[1, y]])\n",
    "print(X)\n",
    "# Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the data that you generated to find something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/wm_dat1.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the training data to the scikit-learn softmax classifier\n",
    "\n",
    "The image above shows that there is considerable overlap between the classes. Use your trained classifier to assign all the training data to different classes.\n",
    "\n",
    "**Print the confusion matrix and also plot it, to get something like the image below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/wm_confusion.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now plot the different classes as predicted by your system. You should get something like:** \n",
    "\n",
    "**Can you tell from the graph that this is a *linear* classifier?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/wm_dat2.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your own Naive Bayes Classifier (from first principles). Train it using the exact same data you used for the previous question (write it in a seperate python file which you can import into the notebook). Implement it in a generic way, i.e. it should be able to work on $d$ dimensional data and it should not be limited to a certain amount of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your trained classifier to assign all the training data to different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix and also plot it, to get something like the image below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/conf_mat_bayes.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now plot the different classes as predicted by your system. You should get something like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/predict_bayes.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement your own Logistic Regression classifier (from first principles). It should be generic and be able to work on $d$ dimensional data (and two classes). Please make your implementation as modular as possible, having a seperate function for the Hessian and the gradient vector (write it in a seperate python file which you can import into the notebook). A regularization term based on a Gaussian prior (with zero mean and covariance matrix $\\lambda\\mathbf{I}$) must be included.  Optionally, a bias term also needs to be incorporated into your classifier - this can be implemented by augmenting the training dataset with an additional all-one feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now train your classifier using the following data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - two randomly-generated Gaussian-distributed clouds of points in 2d space\n",
    "np.random.seed(0)\n",
    "# Number of points\n",
    "N = 1000\n",
    "# Labels for each cluster\n",
    "y = np.random.randint(low=0, high=2, size = N)\n",
    "# Mean of each cluster\n",
    "means = np.array([[-1, 1], [-1, 1],])\n",
    "# Covariance (in X and Y direction) of each cluster\n",
    "covariances = np.random.random_sample((2, 2)) + 1\n",
    "# Dimensions of each point\n",
    "X = np.vstack([np.random.randn(N)*covariances[0, y] + means[0, y],\n",
    "               np.random.randn(N)*covariances[1, y] + means[1, y]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your trained classifier to assign all the training data to different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print the confusion matrix and also plot it, to get something like the image below:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/conf_mat_logreg.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now plot the different classes as predicted by your system. Add your decision boundary to the same plot. You should get something like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/predict_logreg.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Before continuing in the notebook, you will need to install the `lasagne` Python module with \"pip3 install --user lasagne\" **\n",
    "\n",
    "# Now classify the MNIST digits \n",
    "\n",
    "The MNIST database provided in the assignment resources consists of low-resolution (28x28) grayscale images of handwritten digits ($0,1,2,3,4,5,6,7,8,9$). First, you read in a set of training digits and display them interactively to get an idea what they look like. Afterwards, you build and train a softmax classifier using scitkit-image and scikit-learn. You will then classify the digits in the test set and display the results. Finally, you will display the weights as images.\n",
    "\n",
    "First load the dataset - for more information about the dataset, see http://yann.lecun.com/exdb/mnist/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import load_dataset\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the test digits interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "def show_digits(k=0):\n",
    "    \"\"\"\n",
    "    Show the first 1000 digits in the training set\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.imshow(X_train[k][0], cmap=cm.binary)   \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "w = interact(show_digits, k =(0, 1000)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the softmax classifier\n",
    "\n",
    "**Using the training set, build a softmax classifier. Use this classifier to classify the digits in the training set and the test set separately. Print the confusion matrix and also display it as an image for each case to get something like:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./images/wm_confusion2.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "**Calculate the accuracy of your system as a fraction of the correctly classified digits. You should get something like 0.9254. use - `logis(C=1e5, solver='lbfgs', multi_class='multinomial')`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the weights and display as images.\n",
    "\n",
    "**Extract the weights of the softmax classifier and display them as images. Each set of weights should correspond to a specific digit**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As an example the weight image associated with the 0 digit should look similar to this:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='./wm_softmax_mnist_weights/wm_0.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further investigation\n",
    "\n",
    "Fit the softmax classifier for different values of the regularization parameter - we recommend values evenly spaced on the log scale - and show the corresponding weight images for some digit as the parameter changes.  Explain the changes in the weight images observed. Moreover, plot the accuracy of your classifier as a function of the regularization parameter. Use this plot to expand on your answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "1e995b3cf08a4dde89a4f98d36100b4e": {
     "views": []
    },
    "22e8d02e22734631ac89835a3ee6c264": {
     "views": []
    },
    "4d54b6e490414dbcadd95b8a615fb2a1": {
     "views": []
    },
    "62ba560ca58c4da892117bca7f6fa9a9": {
     "views": []
    },
    "8a08ef3f36ff412f8a9a0eb3d66537ca": {
     "views": []
    },
    "8fc28dcd900f40398066d0bb93b4b02d": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "92932ec08bea476e8370722ee5d51d51": {
     "views": []
    },
    "9439499ab9484e05abb40497c8389931": {
     "views": []
    },
    "94be00fa834648e29162ff40ec77694e": {
     "views": []
    },
    "cd5fcc64b09b4b6299c3ef8c66065546": {
     "views": []
    },
    "d0df71b154a740c78d52456923df87a3": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "ff27897c2d224808ad8c6e680968cbb5": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
